"""
Streamlit Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ½ÑÑ‚Ğ¸ÑÑ…
Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ: ÑĞ¾Ğ½, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½, ĞµĞ´Ğ°/Ğ½Ğ°Ğ¿Ğ¸Ñ‚ĞºĞ¸
"""
import os
import cv2
import time
import pickle
import tempfile
import numpy as np
import streamlit as st
from datetime import datetime
from pathlib import Path

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
from modules.detection import ViolationDetector
from modules.face_recognition import FaceRecognizer
from modules.video_processor import VideoProcessor

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ STREAMLIT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title="ğŸ“ ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ Ğ”Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹",
    page_icon="ğŸ“¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ
st.markdown("""
<style>
    /* ĞĞ±Ñ‰Ğ¸Ğ¹ Ñ„Ğ¾Ğ½ */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    /* Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº */
    .main-title {
        color: #2c3e50;
        text-align: center;
        font-size: 2.8em;
        font-weight: 800;
        margin-bottom: 10px;
        text-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .subtitle {
        text-align: center;
        color: #7f8c8d;
        font-size: 1.1em;
        margin-bottom: 30px;
    }
    /* ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº */
    .metric-container {
        background: white;
        padding: 20px;
        border-radius: 16px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.06);
        margin: 12px 0;
        border-left: 4px solid #3498db;
    }
    /* Ğ‘ĞµĞ¹Ğ´Ğ¶Ğ¸ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ */
    .violation-badge {
        display: inline-block;
        padding: 6px 14px;
        border-radius: 50px;
        color: white;
        font-weight: 600;
        font-size: 0.95em;
        margin: 4px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15);
    }
    .sleeping { background: linear-gradient(135deg, #e74c3c, #c0392b); }
    .phone { background: linear-gradient(135deg, #f39c12, #d35400); }
    .food { background: linear-gradient(135deg, #3498db, #2980b9); }
    .bottle { background: linear-gradient(135deg, #9b59b6, #8e44ad); }
    /* Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ¸ */
    div[data-baseweb="tab-list"] {
        gap: 12px;
    }
    div[data-baseweb="tab"] {
        border-radius: 12px !important;
        background: #f8f9fa;
        padding: 8px 16px !important;
        font-weight: 600;
        color: #495057 !important;
        border: none !important;
    }
    div[data-baseweb="tab"][aria-selected="true"] {
        background: #3498db !important;
        color: white !important;
    }
    /* ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ */
    button[kind="primary"] {
        background: linear-gradient(to right, #3498db, #2980b9);
        border: none;
        color: white;
        font-weight: 600;
    }
    button[kind="primary"]:hover {
        background: linear-gradient(to right, #2980b9, #1c6ea4);
    }
    /* ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€ */
    div.stProgress > div > div > div {
        background-color: #3498db;
        height: 12px;
        border-radius: 6px;
    }
    /* Ğ­ĞºÑĞ¿Ğ°Ğ½Ğ´ĞµÑ€Ñ‹ Ğ² Ğ¶ÑƒÑ€Ğ½Ğ°Ğ»Ğµ */
    .streamlit-expanderHeader {
        font-weight: 600 !important;
        background-color: #f1f8ff !important;
        border-radius: 10px !important;
        padding: 10px !important;
    }
</style>
""", unsafe_allow_html=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ SESSION STATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if 'detector' not in st.session_state:
    st.session_state.detector = None

if 'face_recognizer' not in st.session_state:
    st.session_state.face_recognizer = None

if 'video_processor' not in st.session_state:
    st.session_state.video_processor = VideoProcessor()

if 'violations_log' not in st.session_state:
    st.session_state.violations_log = []

if 'processing' not in st.session_state:
    st.session_state.processing = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞšĞ­Ğ¨Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource
def load_detector(model_path):
    """ĞšÑÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹"""
    return ViolationDetector(model_path)

@st.cache_resource
def load_face_recognizer(db_path):
    """ĞšÑÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ»Ğ¸Ñ†"""
    return FaceRecognizer(db_path if os.path.exists(db_path) else None)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_frame_for_detection(current_time, detections, sleep_start_time, sleep_buffer):
    """
    ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ĞºĞ°Ğ´Ñ€Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ confirmed_violations.
    
    Args:
        current_time: Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ
        detections: ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… ĞºĞ»Ğ°ÑÑĞ¾Ğ² {class_name: [...]}
        sleep_start_time: Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ÑĞ½Ğ°
        sleep_buffer: Ğ±ÑƒÑ„ĞµÑ€ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ÑĞ½Ğ° Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
    
    Returns:
        (confirmed_violations, new_sleep_start_time, new_last_detection_time)
    """
    confirmed_violations = set()
    new_sleep_start_time = sleep_start_time
    new_last_detection_time = None
    
    # Ğ›ĞĞ“Ğ˜ĞšĞ Ğ‘Ğ£Ğ¤Ğ•Ğ Ğ Ğ¡ĞĞ: ÑĞ¾Ğ½ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ĞµÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ÑĞ»Ğµ sleep_buffer ÑĞµĞºÑƒĞ½Ğ´
    sleep_detected_in_frame = 'sleeping' in detections
    
    if sleep_detected_in_frame:
        if new_sleep_start_time is None:
            # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ ÑĞ¾Ğ½, ÑÑ‚Ğ°Ñ€Ñ‚ÑƒĞµĞ¼ Ñ‚Ğ°Ğ¹Ğ¼ĞµÑ€
            new_sleep_start_time = current_time
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°, Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾ Ğ»Ğ¸ sleep_buffer ÑĞµĞºÑƒĞ½Ğ´
        if (current_time - new_sleep_start_time) >= sleep_buffer:
            # Ğ¡Ğ¾Ğ½ ĞŸĞĞ”Ğ¢Ğ’Ğ•Ğ Ğ–Ğ”Ğ•Ğ - Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² confirmed_violations
            confirmed_violations.add('sleeping')
            new_last_detection_time = current_time
    else:
        # Ğ¡Ğ¾Ğ½ Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½, ÑĞ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ¹Ğ¼ĞµÑ€
        new_sleep_start_time = None
    
    # Ğ”ĞĞ‘ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ”Ğ Ğ£Ğ“Ğ˜Ğ¥ ĞĞĞ Ğ£Ğ¨Ğ•ĞĞ˜Ğ™ (Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ±ÑƒÑ„ĞµÑ€Ğ°)
    for class_name in detections:
        if class_name != 'sleeping':
            confirmed_violations.add(class_name)
            new_last_detection_time = current_time
    
    return confirmed_violations, new_sleep_start_time, new_last_detection_time


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜ Ğ’Ğ˜Ğ”Ğ•Ğ (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_webcam(video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹"""
    try:
        st.info("â³ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹... (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 3-5 ÑĞµĞºÑƒĞ½Ğ´)")
        
        cap = cv2.VideoCapture(0)  # 0 - Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°
        
        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑƒÑ„ĞµÑ€
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ°
        if not cap.isOpened():
            st.error("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğµ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ĞµÑ‘ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ.")
            st.session_state.processing = False
            return
        
        # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0:
            fps = 30
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None
        recording = False
        rec_violations = set()
        current_segment_path = None
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        st.success("âœ… Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!")
        st.info("ğŸ”„ Ğ¢Ñ€Ğ°Ğ½ÑĞ»ÑÑ†Ğ¸Ñ Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹ (Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸)...")
        stop_button = st.button("â¹ï¸ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞ»ÑÑ†Ğ¸Ñ", key="webcam_stop")
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ¾ Ğ½Ğ°Ğ¶Ğ°Ñ‚Ğ¸Ñ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Stop Ğ¸Ğ»Ğ¸ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚ (9000 ĞºĞ°Ğ´Ñ€Ğ¾Ğ²)
        max_frames = 9000
        
        while cap.isOpened() and frame_count < max_frames and not stop_button:
            ret, frame = cap.read()
            if not ret:
                st.warning("âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹")
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, detections, sleep_start_time, sleep_buffer
                )
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                last_detections = detections
                last_confirmed_violations = confirmed_violations
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€ĞµĞ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                if confirmed_violations and detection_time:
                    last_detection_time = detection_time
            
            # â”€â”€â”€ Ğ›ĞĞ“Ğ˜ĞšĞ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if confirmed_violations:
                if not recording:
                    # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                    filename = st.session_state.video_processor.generate_segment_filename()
                    current_segment_path = os.path.join(segments_dir, filename)
                    
                    st.session_state.video_processor.start_recording(
                        current_segment_path,
                        (width, height),
                        fps
                    )
                    recording = True
                    rec_violations = set(confirmed_violations)
                else:
                    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ (Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸)
                    rec_violations.update(confirmed_violations)
            
            # â”€â”€â”€ Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ ĞšĞĞ”Ğ Ğ• â”€â”€â”€
            # Ğ Ğ¸ÑÑƒĞµĞ¼ Ğ±Ğ¾ĞºÑÑ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ (Ğ¿ĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ğµ last_detections Ğ¸ last_confirmed_violations)
            if last_detections and last_confirmed_violations:
                # Ğ Ğ¸ÑÑƒĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ ĞºĞ»Ğ°ÑÑÑ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹, Ğ¸ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ñ‹
                violations_to_draw = last_confirmed_violations & set(last_detections.keys())
                if violations_to_draw:
                    annotated_frame = st.session_state.detector.draw_detections(
                        annotated_frame, last_detections, violations_to_draw
                    )
            
            # ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # â”€â”€â”€ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞšĞĞĞ§ĞĞĞ˜Ğ¯ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    # ĞšĞĞĞ•Ğ¦ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    
                    # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(sorted(rec_violations)),  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
                    last_confirmed_violations = set()  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼
            
            # ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€)
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ²: {metrics['total_frames']} | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ
            progress = min(frame_count / max_frames, 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        if st.session_state.violations_log:
            st.info("ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False
    
    except Exception as e:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹: {e}")
        st.session_state.processing = False

def process_video_file(video_path, video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None  # Ğ’Ñ€ĞµĞ¼Ñ ĞºĞ¾Ğ³Ğ´Ğ° Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ»Ğ°ÑÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ
        recording = False
        writer = None
        rec_violations = set()
        current_segment_path = None
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ¸ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ²ÑĞµÑ… ĞºĞ°Ğ´Ñ€Ğ°Ñ…
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # â”€â”€â”€ Ğ”Ğ•Ğ¢Ğ•ĞšĞ¦Ğ˜Ğ¯ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ frame_skip ĞºĞ°Ğ´Ñ€) â”€â”€â”€
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, detections, sleep_start_time, sleep_buffer
                )
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                last_detections = detections
                last_confirmed_violations = confirmed_violations
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                if confirmed_violations and detection_time:
                    last_detection_time = detection_time
            
            # â”€â”€â”€ Ğ›ĞĞ“Ğ˜ĞšĞ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if confirmed_violations:
                if not recording:
                    # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                    filename = st.session_state.video_processor.generate_segment_filename()
                    current_segment_path = os.path.join(segments_dir, filename)
                    
                    st.session_state.video_processor.start_recording(
                        current_segment_path,
                        (width, height),
                        fps
                    )
                    recording = True
                    rec_violations = set(confirmed_violations)
                else:
                    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ (Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸)
                    rec_violations.update(confirmed_violations)
            
            # â”€â”€â”€ Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ ĞšĞĞ”Ğ Ğ• â”€â”€â”€
            if recording or last_confirmed_violations:
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ğ¾ĞºÑÑ‹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹
                annotated_frame = st.session_state.detector.draw_detections(
                    annotated_frame, last_detections, last_confirmed_violations
                )
            
            # ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # â”€â”€â”€ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞšĞĞĞ§ĞĞĞ˜Ğ¯ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    # ĞšĞĞĞ•Ğ¦ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    
                    # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(sorted(rec_violations)),  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
                    last_confirmed_violations = set()  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼
            
            # â”€â”€â”€ ĞĞ¢ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ• â”€â”€â”€
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {metrics['total_frames']} ĞºĞ°Ğ´Ñ€Ğ¾Ğ² | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            progress = min(frame_count / (cap.get(cv2.CAP_PROP_FRAME_COUNT)), 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾
        if st.session_state.violations_log:
            st.info("ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¢ĞĞ›Ğ¬ĞšĞ ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                # Ğ•ÑĞ»Ğ¸ Ğ‘Ğ” Ğ»Ğ¸Ñ† Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°, Ğ¾Ñ‚Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ ĞºĞ°Ğº "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¿Ğ¾ÑĞ»Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
    
    except Exception as e:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ¸Ğ´ĞµĞ¾: {e}")
        st.session_state.processing = False  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Ñ‚Ğ¾Ğ¶Ğµ

def process_video_url(url, video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ñ URL"""
    try:
        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚Ğ¾Ğº
        st.info(f"ğŸ”„ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ¿Ğ¾Ñ‚Ğ¾ĞºÑƒ: {url}")
        
        cap = cv2.VideoCapture(url)
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¾Ğ¹
        if not cap.isOpened():
            st.error("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ¿Ğ¾Ñ‚Ğ¾ĞºÑƒ!")
            st.info("""
            **Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:**
            - âŒ ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ URL (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
            - âŒ ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¸Ğ»Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
            - âŒ Ğ¡ĞµÑ‚ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ¸Ğ»Ğ¸ ÑĞ»Ğ°Ğ±Ğ¾Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ
            
            **ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ URL:**
            - RTSP Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `rtsp://...`
            - HTTP Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `http://... Ğ¸Ğ»Ğ¸ https://...`
            - Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `/path/to/video.mp4`
            - ĞĞ¾Ğ¼ĞµÑ€ ĞºĞ°Ğ¼ĞµÑ€Ñ‹: `0` (Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°)
            
            **ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:**
            - `rtsp://admin:password@192.168.1.100:554/stream`
            - `http://example.com/video.m3u8`
            """)
            st.session_state.processing = False
            return
        
        # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹, ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0 or fps is None:
            fps = 30
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        if width == 0:
            width = 1280
        if height == 0:
            height = 720
        
        st.success(f"âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾! Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ: {width}x{height}@{fps}fps")
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None
        recording = False
        rec_violations = set()
        current_segment_path = None
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        st.info("ğŸ”„ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° (Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Stop Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ)...")
        
        # Ğ”Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ² Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¶Ğ¼ÑƒÑ‚ Stop
        max_frames = 3000  # ~100 ÑĞµĞºÑƒĞ½Ğ´ Ğ½Ğ° 30 FPS
        
        while cap.isOpened() and frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ frame_skip ĞºĞ°Ğ´Ñ€Ğ¾Ğ²
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                last_detections = detections
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # CONFIRM: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ±ÑƒÑ„ĞµÑ€Ğ° ÑĞ½Ğ°
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, detections, sleep_start_time, sleep_buffer
                )
                last_confirmed_violations = confirmed_violations
                if confirmed_violations and detection_time:
                    last_detection_time = detection_time
                
                # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒÑ
                if confirmed_violations and not recording:
                    # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                    filename = st.session_state.video_processor.generate_segment_filename()
                    current_segment_path = os.path.join(segments_dir, filename)
                    
                    st.session_state.video_processor.start_recording(
                        current_segment_path,
                        (width, height),
                        fps
                    )
                    recording = True
                    rec_violations = set(confirmed_violations)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ ÑƒĞ¶Ğµ Ğ¸Ğ´ĞµÑ‚
                if confirmed_violations and recording:
                    rec_violations.update(confirmed_violations)
            
            # VISUALIZE: Ğ Ğ¸ÑÑƒĞµĞ¼ Ğ±Ğ¾ĞºÑÑ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹
            if last_detections and last_confirmed_violations:
                violations_to_draw = last_confirmed_violations & set(last_detections.keys())
                if violations_to_draw:
                    annotated_frame = st.session_state.detector.draw_detections(
                        annotated_frame, last_detections, violations_to_draw
                    )
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ (ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ ĞºÑ€ÑƒĞ³)
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    last_recording_end_time = current_time
                    
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(rec_violations),
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
            

            
            # ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€)
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ²: {metrics['total_frames']} | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°)
            progress = min(frame_count / max_frames, 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾
        if st.session_state.violations_log:
            st.info("ğŸ” ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False
    
    except Exception as e:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°: {e}")
        st.session_state.processing = False

def process_violations_data(violations_log):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    import pandas as pd
    return pd.DataFrame(violations_log) if violations_log else None

def generate_report(violations_log, face_db_path):
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚"""
    try:
        if not st.session_state.face_recognizer and os.path.exists(face_db_path):
            st.session_state.face_recognizer = load_face_recognizer(face_db_path)
        
        return st.session_state.video_processor.generate_report(
            violations_log,
            st.session_state.face_recognizer
        )
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°: {e}")
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ™ Ğ˜ĞĞ¢Ğ•Ğ Ğ¤Ğ•Ğ™Ğ¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown('<div class="main-title">ğŸ“ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ”Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹</div>', 
            unsafe_allow_html=True)
st.markdown("""
<div style='text-align: center; color: gray;'>
ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ½ÑÑ‚Ğ¸ÑÑ… 
Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ĞµĞ¹
</div>
""", unsafe_allow_html=True)

# Ğ‘Ğ¾ĞºĞ¾Ğ²Ğ°Ñ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ğ¼Ğ¸
st.sidebar.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸")

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
model_path = st.sidebar.text_input(
    "ğŸ“ ĞŸÑƒÑ‚ÑŒ Ğº Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ YOLO",
    value="best.pt",
    help="ĞŸÑƒÑ‚ÑŒ Ğº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ .pt"
)

if st.sidebar.button("ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", disabled=st.session_state.processing):
    if not st.session_state.processing:
        if os.path.exists(model_path):
            st.session_state.detector = load_detector(model_path)
            st.sidebar.success("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°!")
        else:
            st.sidebar.error(f"âŒ Ğ¤Ğ°Ğ¹Ğ» {model_path} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½!")

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸
st.sidebar.subheader("ğŸ¯ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸")
conf_threshold = st.sidebar.slider(
    "ĞŸĞ¾Ñ€Ğ¾Ğ³ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ (Confidence)",
    min_value=0.0,
    max_value=1.0,
    value=0.2,
    step=0.05,
    help="Ğ§ĞµĞ¼ Ğ²Ñ‹ÑˆĞµ - Ñ‚ĞµĞ¼ ÑÑ‚Ñ€Ğ¾Ğ¶Ğµ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸"
)

frame_skip = st.sidebar.slider(
    "ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº ĞºĞ°Ğ´Ñ€Ğ¾Ğ²",
    min_value=1,
    max_value=10,
    value=2,
    help="ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ N-Ğ¹ ĞºĞ°Ğ´Ñ€ (Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸)"
)

buffer_seconds = st.sidebar.slider(
    "Ğ‘ÑƒÑ„ĞµÑ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ (ÑĞµĞº)",
    min_value=5,
    max_value=30,
    value=10,
    help="Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞµĞºÑƒĞ½Ğ´ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¸ÑÑ‡ĞµĞ·Ğ½Ğ¾Ğ²ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ"
)

sleep_buffer = st.sidebar.slider(
    "Ğ‘ÑƒÑ„ĞµÑ€ ÑĞ½Ğ° (ÑĞµĞº)",
    min_value=5,
    max_value=30,
    value=10,
    help="Ğ¢Ğ°Ğ¹Ğ¼ĞµÑ€ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ÑĞ½Ğ° Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒÑ"
)

# ĞŸĞ°Ñ€Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ğ»Ğ¸Ñ†
st.sidebar.subheader("ğŸ‘¤ Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ¸Ñ†")
face_db_path = st.sidebar.text_input(
    "ğŸ“ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ»Ğ¸Ñ†",
    value="students.pkl",
    help="Ğ¤Ğ°Ğ¹Ğ» Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚Ğ¾Ğ²"
)
face_similarity = st.sidebar.slider(
    "ĞŸĞ¾Ñ€Ğ¾Ğ³ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ»Ğ¸Ñ†Ğ°",
    min_value=0.3,
    max_value=0.9,
    value=0.5,
    step=0.05,
    help="ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ"
)

if st.session_state.detector is None:
    st.warning("âš ï¸ ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹!")
else:
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ¸
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“¹ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾",
        "ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°",
        "ğŸ“ Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹"
    ])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ’ĞšĞ›ĞĞ”ĞšĞ 1: ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ’Ğ˜Ğ”Ğ•Ğ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab1:
        st.header("ğŸ“¹ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾")
        
        col_source, col_options = st.columns([2, 1])
        
        with col_source:
            video_source = st.radio(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ²Ğ¸Ğ´ĞµĞ¾:",
                ["ğŸ“· Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°", "ğŸ“ Ğ’Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»", "ğŸŒ URL Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°"],
                horizontal=True
            )
        
        with col_options:
            if st.button("ğŸ¬ ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ", key="process_btn", disabled=st.session_state.processing):
                if not st.session_state.processing:
                    st.session_state.processing = True
        
        # ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
        video_container = st.container()
        metrics_container = st.container()
        
        if st.session_state.processing:
            
            if video_source == "ğŸ“· Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°":
                process_webcam(video_container, metrics_container,
                             frame_skip, buffer_seconds, sleep_buffer,
                             face_db_path, face_similarity)
            
            elif video_source == "ğŸ“ Ğ’Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»":
                video_file = st.file_uploader(
                    "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»",
                    type=['mp4', 'avi', 'mov', 'mkv']
                )
                if video_file:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
                        tmp.write(video_file.read())
                        process_video_file(tmp.name, video_container, metrics_container, 
                                         frame_skip, buffer_seconds, sleep_buffer, 
                                         face_db_path, face_similarity)
            
            elif video_source == "ğŸŒ URL Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°":
                url = st.text_input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ URL Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°:")
                if url:
                    process_video_url(url, video_container, metrics_container,
                                     frame_skip, buffer_seconds, sleep_buffer,
                                     face_db_path, face_similarity)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ’ĞšĞ›ĞĞ”ĞšĞ 2: Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab2:
        st.header("ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
        
        if st.session_state.violations_log:
            violations_df = process_violations_data(st.session_state.violations_log)
            
            # Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ¸
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹", len(st.session_state.violations_log))
            
            with col2:
                sleeping_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'sleeping' in v['violation'].lower()
                )
                st.metric("ğŸ˜´ Ğ¡Ğ¾Ğ½", sleeping_count)
            
            with col3:
                phone_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'phone' in v['violation'].lower()
                )
                st.metric("ğŸ“± Ğ¢ĞµĞ»ĞµÑ„Ğ¾Ğ½", phone_count)
            
            with col4:
                food_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'food' in v['violation'].lower() or 
                       'bottle' in v['violation'].lower()
                )
                st.metric("ğŸ½ï¸ Ğ•Ğ´Ğ°/ĞĞ°Ğ¿Ğ¸Ñ‚Ğ¾Ğº", food_count)
            
            # Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
            st.subheader("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
            violation_types = {}
            for v in st.session_state.violations_log:
                for vtype in v['violation'].split(', '):
                    violation_types[vtype] = violation_types.get(vtype, 0) + 1
            
            if violation_types:
                import plotly.express as px
                fig = px.bar(
                    x=list(violation_types.keys()),
                    y=list(violation_types.values()),
                    labels={'x': 'Ğ¢Ğ¸Ğ¿ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ', 'y': 'ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾'},
                    color=['#ff6b6b', '#ffa94d', '#74c0fc', '#b197fc'][:len(violation_types)]
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ ÑˆĞºĞ°Ğ»Ğ°
            st.subheader("Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ ÑˆĞºĞ°Ğ»Ğ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
            times = [v['time'] for v in st.session_state.violations_log]
            st.write(f"ĞŸĞµÑ€Ğ²Ğ¾Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ: {times[0] if times else 'N/A'}")
            st.write(f"ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ: {times[-1] if times else 'N/A'}")
            st.write(f"Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾: {len(st.session_state.violations_log)} Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
        
        else:
            st.info("ğŸ“Š ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ°.")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ’ĞšĞ›ĞĞ”ĞšĞ 3: Ğ–Ğ£Ğ ĞĞĞ› ĞĞĞ Ğ£Ğ¨Ğ•ĞĞ˜Ğ™
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab3:
        st.header("ğŸ“ Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
        
        if st.session_state.violations_log:
            # ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¶ÑƒÑ€Ğ½Ğ°Ğ»Ğ¾Ğ¼
            col1, col2, col3 = st.columns([2, 1, 1])
            
            # CSV ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚ - Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ‘Ğ•Ğ— Ğ½ĞµĞ½ÑƒĞ¶Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¾Ğº
            with col2:
                import pandas as pd
                df = pd.DataFrame(st.session_state.violations_log)
                csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ CSV",
                    data=csv,
                    file_name=f"violations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="csv_download_tab3"
                )
            
            with col3:
                if st.button("ğŸ—‘ï¸ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ", disabled=st.session_state.processing):
                    if not st.session_state.processing:
                        st.session_state.violations_log = []
                        st.success("âœ… Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½!")
                        st.rerun()
            
            st.divider()
            
            for i, violation in enumerate(st.session_state.violations_log, 1):
                with st.expander(
                    f"ğŸ”´ ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ #{i} | {violation['time']} | {violation['violation']}"
                ):
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.write(f"**Ğ’Ñ€ĞµĞ¼Ñ:** {violation['time']}")
                        st.write(f"**ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ:** {violation['violation']}")
                        st.write(f"**Ğ¤Ğ°Ğ¹Ğ»:** {Path(violation['path']).name}")
                    
                    with col2:
                        st.write(f"**Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚:** {violation.get('student', 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾')}")
                        st.write(f"**Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:** {violation.get('confidence', 'N/A')}")
                    
                    if os.path.exists(violation['path']):
                        with open(violation['path'], 'rb') as f:
                            st.download_button(
                                label="â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾",
                                data=f.read(),
                                file_name=Path(violation['path']).name,
                                mime="video/mp4",
                                key=f"download_{i}"
                            )
        else:
            st.info("ğŸ“ Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ¿ÑƒÑÑ‚. ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶Ğ°Ñ‚ÑŒÑÑ Ğ·Ğ´ĞµÑÑŒ.")

if __name__ == "__main__":
    pass
